{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PETS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer antes de comenzar con la manipulacion de nuestros datos es importar todas las librerias que vayamos a utlizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join, exists\n",
    "from skimage import data, exposure\n",
    "from os import listdir\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación y preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la organización de las imágenes hemos decidido separar en dos carpetas (una para perros y otra para gatos) todas las imágenes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes organizadas según si es gato o perro.\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio principal con imágenes de gatos\n",
    "gatos_directory = \"images/images\"\n",
    "\n",
    "# Iterar sobre todas las imágenes de gatos\n",
    "for filename in os.listdir(gatos_directory):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Obtener la primera letra del nombre de la raza\n",
    "        primera_letra = filename.split(\"_\")[0][0]\n",
    "\n",
    "        # Determinar la carpeta de destino según la primera letra\n",
    "        carpeta_destino = os.path.join(gatos_directory, \"gatos\" if primera_letra.isupper() else \"perros\")\n",
    "\n",
    "        # Crear la carpeta de destino si no existe\n",
    "        os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "        # Crear la ruta completa a la imagen original y a la nueva ubicación\n",
    "        original_path = os.path.join(gatos_directory, filename)\n",
    "        nueva_ruta = os.path.join(carpeta_destino, filename)\n",
    "\n",
    "        # Mover la imagen a la carpeta correspondiente\n",
    "        shutil.move(original_path, nueva_ruta)\n",
    "\n",
    "print(\"Imágenes organizadas según si es gato o perro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.0.231)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.22.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.9.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.64.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\marcc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\marcc\\anaconda3\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\marcc\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\marcc/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "C:\\Users\\marcc\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "YOLOv5  2023-12-18 Python-3.8.5 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)  # Carrega online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.081909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.59079</td>\n",
       "      <td>310.551605</td>\n",
       "      <td>0.44604</td>\n",
       "      <td>15</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       xmin  ymin       xmax        ymax  confidence  class name\n",
       "0  7.081909   0.0  384.59079  310.551605     0.44604     15  cat"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_yolo(\"images/images/gatos/Abyssinian_110.jpg\") \n",
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes en el conjunto de entrenamiento: 5912\n",
      "Número de imágenes en el conjunto de prueba: 1478\n"
     ]
    }
   ],
   "source": [
    "# Rutas a las carpetas con imágenes de perros y gatos\n",
    "path_gatos = \"images/images/gatos/\"\n",
    "path_perros = \"images/images/perros/\"\n",
    "\n",
    "# Obtén la lista de archivos en cada carpeta y combínalas en una lista única\n",
    "images_gatos = [os.path.join(path_gatos, img) for img in os.listdir(path_gatos) if img.endswith(\".jpg\")]\n",
    "images_perros = [os.path.join(path_perros, img) for img in os.listdir(path_perros) if img.endswith(\".jpg\")]\n",
    "\n",
    "# Combina ambas listas\n",
    "images = images_gatos + images_perros\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir información\n",
    "print(\"Número de imágenes en el conjunto de entrenamiento:\", len(train_images))\n",
    "print(\"Número de imágenes en el conjunto de prueba:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1478/1478 [07:29<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total en el conjunto de prueba: 73.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluar_conjunto(dataset, detect_fn):\n",
    "    correct_counter = 0\n",
    "    total_samples = len(dataset)\n",
    "\n",
    "    for img_path in tqdm(dataset):\n",
    "        results = model_yolo(img_path)  # Realiza la inferencia utilizando YOLO\n",
    "        #results.pandas().xyxy[0]\n",
    "        if detect_fn(results.xyxy[0]):\n",
    "            correct_counter += 1\n",
    "\n",
    "    accuracy = correct_counter / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Evaluar sobre el conjunto de prueba combinado\n",
    "total_test_samples = len(test_images)\n",
    "accuracy_total = evaluar_conjunto(test_images, lambda det: any(det[5] in [16, 15] and det[4] >= 0.2 for det in det))\n",
    "\n",
    "print(f\"Accuracy total en el conjunto de prueba: {accuracy_total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de nuestra propia red \n",
    "Ahora pasaremos a crear nuestra propia red para clasificar perros y gatos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División de Conjunto de Datos en Entrenamiento y Prueba:\n",
    "\n",
    "En aprendizaje automático, es fundamental evaluar el rendimiento de un modelo en datos no utilizados durante el entrenamiento. La división del conjunto de datos en conjuntos de entrenamiento y prueba permite esta evaluación. A continuación, se explica el código utilizado:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader` simplifica el proceso de carga y gestión de datos durante el entrenamiento de modelos de aprendizaje automático, proporcionando una interfaz fácil de usar y eficiente para trabajar con conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes en el conjunto de entrenamiento: 5912\n",
      "Número de imágenes en el conjunto de prueba: 1478\n"
     ]
    }
   ],
   "source": [
    "# Ruta del directorio de datos\n",
    "data_root = r\"images/images\"\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Crear una instancia de ImageFolder\n",
    "dataset = ImageFolder(root=data_root, transform=transform)\n",
    "\n",
    "# Porcentaje de datos para el conjunto de prueba\n",
    "test_size = 0.2\n",
    "\n",
    "# Calcular el número de muestras para el conjunto de prueba\n",
    "test_size = int(test_size * len(dataset))\n",
    "\n",
    "# Calcular el número de muestras para el conjunto de entrenamiento\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Tamaño del lote (batch size) que deseas utilizar\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader para el conjunto de entrenamiento\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# DataLoader para el conjunto de prueba\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Imprimir información\n",
    "print(\"Número de imágenes en el conjunto de entrenamiento:\", len(train_dataset))\n",
    "print(\"Número de imágenes en el conjunto de prueba:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitectura de nuestra red\n",
    "En este punto crearemos la arquitectura de nuestra red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        # Capa convolucional 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # Capa convolucional 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # Capa de pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Capa completamente conectada 1\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)  # Ajusta según tu nuevo tamaño de imagen\n",
    "        # Capa de Dropout para regularización\n",
    "        self.dropout = nn.Dropout(0.5)  # Puedes ajustar la probabilidad de dropout\n",
    "        # Capa completamente conectada 2 (salida)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 clases: perro y gato\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aplicar capas convolucionales y de pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)  # Ajusta según tu nuevo tamaño de imagen\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Aplicar Dropout\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos creado la arquitectura de nuestra red pasaremos a crear los métodos que entrenaran y testearan dicha arquitectura. Estas funciones se utilizan en el bucle de entrenamiento para actualizar los parámetros del modelo y evaluar su rendimiento, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) # !!!\n",
    "    print(\"Trainable Parameters: \", pytorch_total_params)\n",
    "    model.train()\n",
    "    loss_v = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "        loss_v += loss.item()\n",
    "\n",
    "    loss_v /= len(train_loader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(loss_v))\n",
    "\n",
    "    return loss_v\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento y evaluacion de la red\n",
    "Se realiza un bucle a lo largo de las épocas. En cada época, se entrena el modelo en el conjunto de entrenamiento y se evalúa en el conjunto de prueba. Los resultados se almacenan en arreglos para análisis posterior.\n",
    "\n",
    "En la primera prueba que realizaremos utilizaremos el optimizador *Adam* y un *learning reate* de 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 0 [0/5912 (0%)]\tLoss: 0.679923\n",
      "Train Epoch: 0 [3200/5912 (54%)]\tLoss: 0.625762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 1 [0/5912 (0%)]\tLoss: 0.594512\n",
      "Train Epoch: 1 [3200/5912 (54%)]\tLoss: 0.563262\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 2 [0/5912 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 2 [3200/5912 (54%)]\tLoss: 0.719512\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 3 [0/5912 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 3 [3200/5912 (54%)]\tLoss: 0.625762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 4 [0/5912 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 4 [3200/5912 (54%)]\tLoss: 0.750762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 5 [0/5912 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 5 [3200/5912 (54%)]\tLoss: 0.625762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 6 [0/5912 (0%)]\tLoss: 0.500762\n",
      "Train Epoch: 6 [3200/5912 (54%)]\tLoss: 0.625762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 7 [0/5912 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 7 [3200/5912 (54%)]\tLoss: 0.657012\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 8 [0/5912 (0%)]\tLoss: 0.563262\n",
      "Train Epoch: 8 [3200/5912 (54%)]\tLoss: 0.532012\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 9 [0/5912 (0%)]\tLoss: 0.657012\n",
      "Train Epoch: 9 [3200/5912 (54%)]\tLoss: 0.719512\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 10 [0/5912 (0%)]\tLoss: 0.782012\n",
      "Train Epoch: 10 [3200/5912 (54%)]\tLoss: 0.657012\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 11 [0/5912 (0%)]\tLoss: 0.563262\n",
      "Train Epoch: 11 [3200/5912 (54%)]\tLoss: 0.563262\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 12 [0/5912 (0%)]\tLoss: 0.719512\n",
      "Train Epoch: 12 [3200/5912 (54%)]\tLoss: 0.750762\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 13 [0/5912 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 13 [3200/5912 (54%)]\tLoss: 0.844512\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n",
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 14 [0/5912 (0%)]\tLoss: 0.688262\n",
      "Train Epoch: 14 [3200/5912 (54%)]\tLoss: 0.563262\n",
      "\n",
      "Train set: Average loss: 0.0200\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6319, Accuracy: 1007/1478 (68%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(33)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "epochs = 15\n",
    "lr = 1e-1\n",
    "\n",
    "model = CustomNet().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Guardar los valores de pérdida promedio de cada iteración (época)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos trazar un gráfico para evaluar como ha ido el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Resultats de l'entrenament\")\n",
    "plt.plot(range(1, (epochs + 1)), train_l,  c=\"red\", label=\"train\")\n",
    "plt.plot(range(1,  (epochs + 1)), test_l,  c=\"green\", label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion probaaremos a volver a entrenar nuestra red pero cambiando algunos de los parametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:  25709314\n",
      "Train Epoch: 0 [0/5912 (0%)]\tLoss: 0.679923\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(33)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.1\n",
    "\n",
    "model = CustomNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Guardar los valores de pérdida promedio de cada iteración (época)\n",
    "train_l = np.zeros((epochs))\n",
    "test_l = np.zeros((epochs))\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    train_l[epoch] = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_l[epoch]  = test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Resultats de l'entrenament\")\n",
    "plt.plot(range(1, (epochs + 1)), train_l,  c=\"red\", label=\"train\")\n",
    "plt.plot(range(1,  (epochs + 1)), test_l,  c=\"green\", label=\"test\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion de razas de perros y gatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar este problema haremos uso de nuestra propia red pero modificandola ligeramente para que pueda clasificar mas clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesing \n",
    "Primero de todo lanzaremos un script para subdividir las carpetas de las dos especies que tenemos en mas carpetas internas para cada raza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes organizadas por raza.\n",
      "Imágenes organizadas por raza.\n"
     ]
    }
   ],
   "source": [
    "def dividir_por_raza(type):\n",
    "    # Ruta al directorio principal con imágenes de gatos\n",
    "    gatos_directory = \"images/images/\"+type\n",
    "\n",
    "    # Iterar sobre todas las imágenes de gatos\n",
    "    for filename in os.listdir(gatos_directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Extraer el nombre de la raza de la imagen\n",
    "            raza, _ = os.path.splitext(filename.split(\"_\")[0])\n",
    "\n",
    "            # Crear la ruta completa a la imagen original y a la nueva ubicación\n",
    "            original_path = os.path.join(gatos_directory, filename)\n",
    "            nueva_carpeta = os.path.join(gatos_directory, raza)\n",
    "\n",
    "            # Crear la carpeta para la raza si no existe\n",
    "            os.makedirs(nueva_carpeta, exist_ok=True)\n",
    "\n",
    "            # Mover la imagen a la carpeta correspondiente\n",
    "            nueva_ruta = os.path.join(nueva_carpeta, filename)\n",
    "            shutil.move(original_path, nueva_ruta)\n",
    "\n",
    "    print(\"Imágenes organizadas por raza.\")\n",
    "    \n",
    "dividir_por_raza(\"perros\")\n",
    "dividir_por_raza(\"gatos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
